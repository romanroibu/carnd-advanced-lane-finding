{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lane_finding import *\n",
    "from lane_finding import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Camera Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = Camera()\n",
    "\n",
    "camera.calibrate(images=[Image.read(fpath) for fpath in glob.glob(\"camera/calibration*.jpg\")],\n",
    "                 pattern_size=(9,6))\n",
    "\n",
    "# Pipeline Step: Undistort image\n",
    "def step_undistort_image(image: Image) -> Image:\n",
    "    return camera.undistort(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_image = Image.read('camera/calibration5.jpg')\n",
    "undistorted_image = step_undistort_image(calibration_image)\n",
    "\n",
    "utils.show_images([\n",
    "    (\"Original\", calibration_image),\n",
    "    (\"Undistorted\", undistorted_image),\n",
    "], save_path='output/images/undistorted.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curved_test_image = Image.read('input/images/curved3.jpg')\n",
    "transformed_image = step_undistort_image(curved_test_image)\n",
    "\n",
    "utils.show_images([\n",
    "    (\"Original\", curved_test_image),\n",
    "    (\"Transformed\", transformed_image),\n",
    "], save_path='output/images/transformed.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Color Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline Step: Generate binary image to detect lanes\n",
    "def step_generate_binary_image(image: Image) -> BinaryImage:\n",
    "    return image.s_channel().binary((170, 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholded_image = step_generate_binary_image(curved_test_image)\n",
    "\n",
    "utils.show_images([\n",
    "    (\"Original\", curved_test_image),\n",
    "    (\"Thresholded\", thresholded_image),\n",
    "], save_path='output/images/thresholded.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Perspective transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perspective = Perspective( #FIXME: Inspect image to get better points\n",
    "    src=[ (200, 700), (600, 450), (700, 450), (1170, 700) ],\n",
    "    dst=[ (370, 700), (370,   0), (970,   0), ( 970, 700) ])\n",
    "\n",
    "# Pipeline Step: Apply perspective tranform to binary image\n",
    "def step_apply_perspective_transform(image: Image) -> Image:\n",
    "    return perspective.transform(image)\n",
    "\n",
    "# Pipeline Step: Apply inverse perspective transform to lane overlay\n",
    "def step_apply_inverse_perspective_transform(image: Image) -> Image:\n",
    "    return perspective.inverse(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warped_image = step_apply_perspective_transform(curved_test_image)\n",
    "\n",
    "utils.show_images([\n",
    "    (\"Original\", curved_test_image),\n",
    "    (\"Warped\", warped_image),\n",
    "], save_path='output/images/warped.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pipeline():\n",
    "\n",
    "    def __init__(self):\n",
    "        self._finder = LaneFinder()\n",
    "\n",
    "    def __call__(self, image: Image) -> Image:\n",
    "        # Return the last image in the processing pipeline\n",
    "        return self.processed_images(image)[-1]\n",
    "\n",
    "    def processed_images(self, image: Image) -> [Image]:\n",
    "        images = []\n",
    "\n",
    "        # Undistort input image\n",
    "        image = step_undistort_image(image)\n",
    "        images.append(image)\n",
    "\n",
    "        # Generate binary image from undistorted image\n",
    "        binary = step_generate_binary_image(image)\n",
    "        images.append(binary)\n",
    "\n",
    "        # Apply perspective transform to binary image\n",
    "        binary = step_apply_perspective_transform(binary)\n",
    "        images.append(binary)\n",
    "\n",
    "        # Find lanes in binary image\n",
    "        lanes, _ = self._finder.search(image=binary)\n",
    "\n",
    "        # Generate an overlay image with lanes and apply inverse perspective transform\n",
    "        overlay_lane = self._finder.overlay(image=binary, lanes=lanes)\n",
    "        overlay_lane = step_apply_inverse_perspective_transform(overlay_lane)\n",
    "        images.append(overlay_lane)\n",
    "\n",
    "        # Generate an overlay image with curvature and offset info\n",
    "        overlay_info = self._finder.overlay_info(image=binary, lanes=lanes)\n",
    "        images.append(overlay_info)\n",
    "\n",
    "        # Combine undistorted input image with lane and info overlays\n",
    "        image = Image.combine(image, 1, overlay_lane, 0.3)\n",
    "        image = Image.combine(image, 1, overlay_info, 1.0)\n",
    "        images.append(image)\n",
    "\n",
    "        return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process image from ./input/images directory and save it to ./output/images\n",
    "def process_image(fname):\n",
    "\n",
    "    input_path  = os.path.join(os.curdir, 'input',  'images', fname)\n",
    "    output_path = os.path.join(os.curdir, 'output', 'images', fname)\n",
    "\n",
    "    pipeline = Pipeline()\n",
    "\n",
    "    image = Image.read(input_path)\n",
    "\n",
    "    output = pipeline(image)\n",
    "\n",
    "    utils.show_images([\n",
    "        (\"\", output),\n",
    "    ], save_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_image('curved3.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process video from ./input/videos directory and save it to ./output/videos\n",
    "# If write_gif is True, save a GIF version to ./output/videos\n",
    "def process_video(fname, subclip_end=None, write_gif=False):\n",
    "\n",
    "    input_path  = os.path.join(os.curdir, 'input',  'videos', fname)\n",
    "    output_path = os.path.join(os.curdir, 'output', 'videos', fname)\n",
    "\n",
    "    pipeline = Pipeline()\n",
    "\n",
    "    clip = Video.read(input_path)\n",
    "\n",
    "    if subclip_end is not None:\n",
    "        clip = clip.subclip(end=subclip_end)\n",
    "\n",
    "    clip = clip.process(pipeline)\n",
    "\n",
    "    clip.write(output_path)\n",
    "    \n",
    "    if write_gif:\n",
    "        gif_path = os.path.splitext(output_path)[0] + '.gif'\n",
    "        clip.write_gif(gif_path)\n",
    "\n",
    "    return utils.show_video(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_video('project.mp4', subclip_end=0.1, write_gif=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.show_video('./input/videos/challenge.mp4')\n",
    "# process_video('challenge.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.show_video('./input/videos/harder_challenge.mp4')\n",
    "# process_video('harder_challenge.mp4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
